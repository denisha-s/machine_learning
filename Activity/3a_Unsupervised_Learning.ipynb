{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSCI 470 Activities and Case Studies\n",
    "\n",
    "1. For all activities, you are allowed to collaborate with a partner. \n",
    "1. For case studies, you should work individually and are **not** allowed to collaborate.\n",
    "\n",
    "By filling out this notebook and submitting it, you acknowledge that you are aware of the above policies and are agreeing to comply with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some considerations with regard to how these notebooks will be graded:\n",
    "\n",
    "1. Cells in which \"# YOUR CODE HERE\" is found are the cells where your graded code should be written.\n",
    "2. In order to test out or debug your code you may also create notebook cells or edit existing notebook cells other than \"# YOUR CODE HERE\". We actually highly recommend you do so to gain a better understanding of what is happening. However, during grading, **these changes are ignored**. \n",
    "2. You must ensure that all your code for the particular task is available in the cells that say \"# YOUR CODE HERE\"\n",
    "3. Every cell that says \"# YOUR CODE HERE\" is followed by a \"raise NotImplementedError\". You need to remove that line. During grading, if an error occurs then you will not receive points for your work in that section.\n",
    "4. If your code passes the \"assert\" statements, then no output will result. If your code fails the \"assert\" statements, you will get an \"AssertionError\". Getting an assertion error means you will not receive points for that particular task.\n",
    "5. If you edit the \"assert\" statements to make your code pass, they will still fail when they are graded since the \"assert\" statements will revert to the original. Make sure you don't edit the assert statements.\n",
    "6. We may sometimes have \"hidden\" tests for grading. This means that passing the visible \"assert\" statements is not sufficient. The \"assert\" statements are there as a guide but you need to make sure you understand what you're required to do and ensure that you are doing it correctly. Passing the visible tests is necessary but not sufficient to get the grade for that cell.\n",
    "7. When you are asked to define a function, make sure you **don't** use any variables outside of the parameters passed to the function. You can think of the parameters being passed to the function as a hint. Make sure you're using all of those variables.\n",
    "8. Finally, **make sure you run \"Kernel > Restart and Run All\"** and pass all the asserts before submitting. If you don't restart the kernel, there may be some code that you ran and deleted that is still being used and that was why your asserts were passing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning - Overview\n",
    "\n",
    "In this exercise we'll look at data clustering and how we evaluate the results. We'll be using synthetic data with only two features, so we can easily visualize them and see what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, homogeneity_completeness_v_measure, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create synthetic data including ground truth class labels\n",
    "\n",
    "First, we'll create synthetic data with classes that form visually evident clusters, but also some overlap between samples from different ground truth classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "X, y = make_blobs(n_samples=n, centers=3, n_features=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], marker='o', c=y, s=25, edgecolor='k')\n",
    "plt.title(\"3 classes of data\")\n",
    "plt.xlabel(\"x_1\")\n",
    "plt.ylabel(\"x_2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering\n",
    "\n",
    "Instead of performing classification on this problem, we can withhold the labels from our model and apply a clustering algorithm instead. Let's apply [KMeans](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) to this example and predict the clusters each point will belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ecf3c7f518a86b7475c3ecab0512749e",
     "grade": false,
     "grade_id": "cell-4e365d0ffa423315",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a model named `model` using KMeans with k = 3\n",
    "# Fit the model to the training data\n",
    "# Predict the classes of the test data and save those as `y_pred`\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2e45ea7747cfa486be8abf1466c405f",
     "grade": true,
     "grade_id": "cell-bd97498a7f778ba4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(model.cluster_centers_) == 3\n",
    "assert len(y_pred) == len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the learned cluster centroids using the `cluster_centers_` attribute of the trained model. Let's plot the centroids on top of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = model.cluster_centers_\n",
    "plt.scatter(X[:, 0], X[:, 1], marker='o', c=y, s=25, edgecolor='k')\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], marker=\"x\", c=\"r\")\n",
    "plt.title(\"3 classes of data with cluster centroids\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: Contingency Table\n",
    "\n",
    "Now that we have our predictions, we can determine how well our model works using a variety of metrics for unsupervised learning. First, let's create the contingency table/matrix for our data. __This is similar to a confusion matrix but the diagonal is irrelevant as the cluster names won't necessarily align with the original classes.__ In addition, the contigency matrix is not necessarily square, because the number of true classes may not be equal to the number of clusters (though they are in this case, since we specified `n_clusters=3`).\n",
    "\n",
    "The following may be useful:\n",
    "\n",
    "- Python Sets - [sets](https://docs.python.org/3.6/tutorial/datastructures.html)\n",
    "- Creating a matrix with all zeros: [np.zeros](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html)\n",
    "- Boolean indexing with numpy: [indexing](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.indexing.html)\n",
    "- Logic operations on numpy arrays: [logic operations](https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.logic.html#logical-operations)\n",
    "\n",
    "Creating the contingency matrix may not be very straightforward so we've provided a hint for you in case you need it. **We recommend you try to solve it on your own first** but if you're completely stuck, check out the hint below.\n",
    "\n",
    "Note that the inputs you are given to the function are two sets of sample labelings. Each labeling contains `n` points' labels where each label is the index of the grouping they belong to.\n",
    "\n",
    "<br>\n",
    "<details>\n",
    "<summary>Click here for a hint</summary>\n",
    "    \n",
    "There are many approaches to do this and we've outlined 2 approaches that you can think of. The first approach goes through the data and figures out where each sample should be counted in the matrix. The second approach goes through the matrix and determines what the value should be at each location.\n",
    "    \n",
    "    \n",
    "For both approaches, we start by creating an empty matrix:\n",
    "    \n",
    "1. Determine the number of unique elements (classes or clusters) of y1 and y2. \n",
    "    \n",
    "2. Initialize a matrix of zeros, with shape equal to (number of unique y1 elements, number of unique y2 elements). \n",
    "\n",
    "    \n",
    "Approach 1: Samples based\n",
    "\n",
    "1. Iterate over each sample\n",
    "2. Add 1 to the location in the matrix where that sample belongs\n",
    "    \n",
    "Approach 2: Matrix based\n",
    "    \n",
    "1. Iterate over each element in the matrix using a pair of nested for loops. \n",
    "    \n",
    "2. For each matrix element, use `np.logical_and()` to help you count the number of y1 elements that fall in that row's class/cluster and the number of y2 elements that fall in that column's class/cluster.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c446db7b7d7bc9493f2b79f12b18e21d",
     "grade": false,
     "grade_id": "cell-6c642ff1d5219b74",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def contingency_table(y_1, y_2):\n",
    "    \"\"\"Determine the contingency table/matrix based on two sets of element groupings\n",
    "    \n",
    "    Args:\n",
    "        y_1 (iterable): A labeling of elements into clusters\n",
    "        y_2 (iterable): Another labeling of elements into clusters\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: A matrix with shape n_groups_y1, n_groups_y2 listing the number of \n",
    "                    elements from one cluster in y1 that are also in one cluster in y2 \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf322fd252a4500eefa8aa08d727d1b9",
     "grade": true,
     "grade_id": "cell-5ae5cc99583ff5e1",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_cont = contingency_table(np.array([0,0,1,2,2]), np.array([1,1,1,0,2]))\n",
    "assert test_cont.shape == (3,3)\n",
    "assert np.all(test_cont.T == contingency_table(np.array([1,1,1,0,2]), np.array([0,0,1,2,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine our model's performance scores based on the other metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Our model has an adjusted rand index of {adjusted_rand_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Our model has an adjusted mutual information score of {adjusted_mutual_info_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,c,v = homogeneity_completeness_v_measure(y_test, y_pred)\n",
    "\n",
    "print(f\"Our model has a homogeneity score of {h:.4f}, completeness score of {c:.4f}, and a v-measure of {v:.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: Silhoutte Score\n",
    "\n",
    "Now let's use the silhoutte score and a hyperparameter search on the validation data to determine the best value of k for KMeans. We already expect it to be 3 since we know that is the ground truth however that doesn't mean we are guaranteed the highest score at $k=3$.\n",
    "\n",
    "The best way to understand the silhoutte score is to examine how it is computed. The treatment at [scikit-learn.org](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html) is nice, and you can also read the [Wikipedia](https://en.wikipedia.org/wiki/Silhouette_(clustering)) entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc4c76001d105fe5f4bff8a95c992fb8",
     "grade": false,
     "grade_id": "cell-f95520c4e18c3498",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def score_ks(ks, features):\n",
    "    \"\"\"Get silhoutte scores by applying KMeans to a set of features with a variety of k values \n",
    "    \n",
    "    Args:\n",
    "        ks (iterable): List of k values to experiment with\n",
    "        features (iterable): The features to train the model on\n",
    "    \n",
    "    Returns:\n",
    "        iterable: A list of scores of models trained using each value of k\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [2,3,4,5,6,10]\n",
    "scores = score_ks(ks, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca95864bdee6f03af78d19f5e13de929",
     "grade": true,
     "grade_id": "cell-2cb9ba46d378fd5a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(scores) == len(ks)\n",
    "assert scores[1] == max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxScore = 0\n",
    "bestK = ks[0]\n",
    "for k, score in zip(ks, scores):\n",
    "    if score > maxScore:\n",
    "        bestK = k\n",
    "        maxScore = score\n",
    "    print(f\"With k = {k}, the silhoute score is {score:.4f}\")\n",
    "    \n",
    "print(f\"\\n\\nThe best k value is k={bestK}, scoring {maxScore:.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ks, scores)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"silhoutte score\")\n",
    "plt.title(\"Silhoutte scores of KMeans clustering\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the \"right\" value for k in a given K-means clustering problem?\n",
    "\n",
    "When we have unlabeled data, there may be no \"right\" value for k. We thus do our best, using a heuristic measure that helps us determine a \"good\" value. That is the purpose served by the silhouette score. Try changing the number of blobs generated in the data and see if the silhouette score always give us a value for k that is equal to the number of ground truth classes in our synthetic data. It won't!\n",
    "\n",
    "__Also observe how the contingency matrix looks when you try different values of clusters versus classes.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed936ab53a1391c5e6af8df699a1dbf5",
     "grade": false,
     "grade_id": "feedback",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def feedback():\n",
    "    \"\"\"Provide feedback on the contents of this exercise\n",
    "    \n",
    "    Returns:\n",
    "        string\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f39f6185a54850c2f1f9b5b2a17b7543",
     "grade": true,
     "grade_id": "feedback-tests",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
